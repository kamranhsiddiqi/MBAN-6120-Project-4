{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helpful guide https://www.dataquest.io/blog/streaming-data-python/\n",
    "\n",
    "#If you haven't already done so, visit the Twitter Developer Center and create a developer account. This account will enable us to create credentials that let us authenticate with the Twitter Streaming API.\n",
    "#Once you create your application on Twitter, you can click on the \"Keys and Access Tokens\" tab to get your credentials. You'll need to get the following from under \"Application Settings\":\n",
    "\n",
    "#Consumer Key (API Key) — we'll refer to this as TWITTER_APP_KEY.\n",
    "twitter_app_key = ' '\n",
    "#Consumer Secret (API Secret) — we'll refer to this as TWITTER_APP_SECRET.\n",
    "twitter_app_secret = ' '\n",
    "\n",
    "#You'll also need to do the following in the section under \"Your Access Token\":\n",
    "#Click \"Create my access token\"\n",
    "#Get the value called Access Token — we'll refer to this as TWITTER_KEY.\n",
    "twitter_key = ' '\n",
    "#Get the value called Access Token Secret — we'll refer to this as TWITTER_SECRET.\n",
    "twitter_secret = ' '\n",
    "\n",
    "\n",
    "#IMPORT NECESSARY PACKAGES#\n",
    "###########################\n",
    "\n",
    "#There are a variety of clients for the Twitter Streaming API across all major programming languages. For Python, there are quite a few, which you can find here. The most popular is tweepy, which allows you to connect to the streaming API and handle errors properly.\n",
    "import tweepy #note you may need to install tweepy first by going to CMD and running pip install tweepy\n",
    "\n",
    "#Once we have all the data we want on each tweet, we're ready to store it for later processing. It's possible to store our data in a csv file, but a csv file makes it hard to query the data. If we want to read from a csv file, we either have to load the whole thing, or go through a convoluted process to query and only load the pieces we want. A good place to store our data is in a database. Because they are commonly used and easy to query, we'll use a relational database. SQLite is the simplest to use major relational database, as it doesn't require any processes to be running, and everything is stored in a single file. In order to access the database, we'll use the dataset package, which makes it extremely simple to access a database and store data. Instead of creating a database and tables, we simply store data, and the dataset package will take care of automatically creating the database and all the tables we need. \n",
    "import dataset\n",
    "\n",
    "#In order to perform sentiment analysis, we can use a library called TextBlob, which allows us to do sentiment analysis in Python, among other natural language processing tasks.\n",
    "from textblob import TextBlob\n",
    "\n",
    "############################\n",
    "\n",
    "#We have to connect to our database using a connection string:\n",
    "db = dataset.connect(\"sqlite:///tweets.db\") #This will create a database called \"tweets.db\" in the same folder as this program\n",
    "\n",
    "#We can setup tweepy to authenticate with Twitter with the following code:\n",
    "auth = tweepy.OAuthHandler(twitter_app_key, twitter_app_secret)\n",
    "auth.set_access_token(twitter_key, twitter_secret )\n",
    "\n",
    "#Then, we can create an API object to pull data from Twitter — we'll pass in the authentication:\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#As we noted above, opening a Twitter stream using tweepy requires a user-defined listener class. We'll need to subclass the StreamListener class, and implement some custom logic. The StreamListener class has a method called on_data. This method will automatically figure out what kind of data Twitter sent, and call an appropriate method to deal with the specific data type. It's possible to deal with events like users sending direct messages, tweets being deleted, and more. For now, we only care about when users post tweets. Thus, we'll need to override the on_status method:\n",
    "class StreamListener(tweepy.StreamListener):\n",
    "     \n",
    "    def on_status(self, status):\n",
    "        #Modify the on_status function to filter out retweets. If the retweeted_status property exists, then don't process the tweet. \n",
    "        if hasattr(status, 'retweeted_status'): #if status.retweeted_status (as shown in the dataquest guide) didn't work so use this instead https://stackoverflow.com/questions/27095950/tweepy-finding-the-original-author-of-a-retweet\n",
    "            return\n",
    "        else: #do the following for all tweets that aren't retweets\n",
    "            print(\"New Tweet:\")\n",
    "            \n",
    "            #print text of tweet\n",
    "            print(status.text)\n",
    "            \n",
    "            #Initialize the TextBlob class on the text of the tweet.\n",
    "            blob = TextBlob(status.text)\n",
    "            \n",
    "            #Get the sentiment score from the class.\n",
    "            sent = blob.sentiment\n",
    "            \n",
    "            #we have already created a database called \"tweets\" using the dataset package we imported earlier\n",
    "            db[\"tweets\"].insert(dict( #insert the following data for each tweet into the tweets database\n",
    "                text=status.text, #creates a column called 'text' and inserts text of tweet\n",
    "                polarity=sent.polarity, #creates a a column called 'polarity' and inserts polarity of the tweet.  polarity is the negativity or positivity of the tweet, on a -1 to 1 scale.\n",
    "                subjectivity=sent.subjectivity, #create a column called 'subjectivity' and inserts subjectivity of the tweet.  subjectivity is how objective or subjective the tweet is. 0 means that the tweet is very objective, and 1 means that it is very subjective.\n",
    "            ))\n",
    "\n",
    "    #We'll also need to override the on_error method of StreamListener so that we can handle errors coming from the Twitter API properly. The Twitter API will send a 420 status code if we're being rate limited. If this happens, we'll want to disconnect. If it's any other error, we'll keep going:\n",
    "    def on_error(self, status_code):\n",
    "        if status_code == 420:\n",
    "            return False\n",
    "        \n",
    "#Create an instance of our StreamListener class.\n",
    "stream_listener = StreamListener()\n",
    "\n",
    "#Create an instance of the tweepy Stream class, which will stream the tweets.\n",
    "#We pass in our authentication credentials (api.auth) so that Twitter allows us to connect.\n",
    "#We pass in our stream_listener so that our callback functions are called.\n",
    "stream = tweepy.Stream(auth=api.auth, listener=stream_listener)\n",
    "\n",
    "#Start streaming tweets by calling the filter method. This will start streaming tweets from the filter.json API endpoint, and passing them to our listener callback.\n",
    "#We pass in a list of terms to filter on, as the API requires.\n",
    "stream.filter(languages=['en'],track=[\"Tesla\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, -0.65, u'Every time you idiots come out with something like this you are proven wrong by his quarterly earnings. Just stop i\\u2026 https://t.co/ad3bJcgzxd', 0.8500000000000001)\n",
      "(2, 0.0, u\"Tesla's Fundraising Options Get Thornier https://t.co/BrUu6MyIna\", 0.0)\n",
      "(3, 0.2, u'Tesla with Autopilot slams into truck stopped at red light - KLAS-TV https://t.co/sHd9VPZRxx via @meetinnovation #tesla', 0.35)\n",
      "(4, 0.0, u'US had total of 180,000 vehicle burning accidents per year out of 280 million ICE vehicles on the road= 0.064%. Tes\\u2026 https://t.co/TMW4tOXLBE', 0.75)\n",
      "(5, 0.0, u'Tesla Model 3 delays may stretch on as engineering lead takes a break https://t.co/viJS98ZutC', 0.0)\n",
      "(6, 0.0, u'Police probe whether Autopilot feature was on in #Tesla crash - Washington Post https://t.co/AuEDnjMeU2', 0.0)\n",
      "(7, 0.0, u'Tesla Model 3 delays may stretch on as engineering lead takes a break https://t.co/EAmGvvGl4D', 0.0)\n",
      "(8, 0.5, u'As the crowds in the streets arrive here I have to remember tomorrow I might not be able to work on @Tesla boy , Mr\\u2026 https://t.co/1HmLshrDkJ', 0.625)\n",
      "(9, 0.5, u'As the crowds in the streets arrive here I have to remember tomorrow I might not be able to work on @Tesla boy , Mr\\u2026 https://t.co/6BtvsS7J6p', 0.625)\n",
      "(10, 0.0, u'Check out Will Tesla\\u2019s music! #TeamAlpha https://t.co/yP60Q1cNRm', 0.0)\n",
      "(11, 0.0, u\"Tesla's Fundraising Options Get Thornier https://t.co/XKNYmpu5o7\", 0.0)\n",
      "(12, -0.04999999999999999, u'Truly unfortunate how Tesla discovered how to provide free worldwide energy and we shut him up and hid his research\\u2026 https://t.co/8fpcE4oGia', 0.9)\n",
      "(13, 0.0, u\"Tesla's Fundraising Options Get Thornier https://t.co/a6jMVKOwiv\", 0.0)\n",
      "(14, 0.0, u'Tesla girl (Extended mix)Orchestran manoeuvrest in the darkhttp://www.radiojekyll.com', 0.0)\n",
      "(15, 0.35, u'@MITSloan @elonmusk was critical of us too. Perhaps some supply chain help would have been good for @Tesla ?', 0.7000000000000001)\n"
     ]
    }
   ],
   "source": [
    "#import dataset\n",
    "import sqlite3\n",
    "conn = sqlite3.connect('tweets.db')\n",
    "c = conn.cursor()\n",
    "for row in c.execute('SELECT * FROM tweets'):\n",
    "        print row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
